*********************************************************************************
*************************************binary *************************************
*********************************************************************************
##### connect with kaggle & download ######
from google.colab import files
uploaded = files.upload()
for fn in uploaded.keys():
  print('User uploaded file "{name}" with length {length} bytes'.format(
      name=fn, length=len(uploaded[fn])))

!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download  --force mohamedhanyyy/chest-ctscan-images

##### import  necessary library ######

import numpy as np
import pandas as pd
import cv2
import matplotlib.pyplot as plt
import seaborn as sns
import os
from skimage import io
from skimage.color import rgb2gray
import plotly.express as px
import random
from sklearn.utils import shuffle
import shutil
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import OneHotEncoder
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential
from keras.layers import Dense, Flatten, Dropout, BatchNormalization, Conv2D, MaxPooling2D
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.applications.resnet import preprocess_input
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from keras import optimizers
from keras.applications import resnet

##### folder path ######

train_path = "/content/Data/train"
valid_path = "/content/Data/valid"
test_path = "/content/Data/test"

########### unzip ##########

from zipfile import ZipFile
file_name = "/content/chest-ctscan-images.zip"
with ZipFile(file_name,'r') as zip:
  zip.extractall()
  print('Done')

############################# pre-processed applying clahe #####################

import cv2
import os

def apply_clahe(image):
    clip_limit = 2.5
    tile_size = (8, 8)
    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_size)
    return clahe.apply(image)

train_dir = "/content/Data/train"
test_dir = "/content/Data/test"
valid_dir = "/content/Data/valid"

train_processed_dir = "/content/Data/train_processed"
test_processed_dir = "/content/Data/test_processed"
valid_processed_dir = "/content/Data/valid_processed"

os.makedirs(train_processed_dir, exist_ok=True)
os.makedirs(test_processed_dir, exist_ok=True)
os.makedirs(valid_processed_dir, exist_ok=True)

for subdir in os.listdir(train_dir):
    subdir_path = os.path.join(train_dir, subdir)
    if os.path.isdir(subdir_path):
        print(f'Applying CLAHE to images in {subdir_path}...')
        for filename in os.listdir(subdir_path):
            file_path = os.path.join(subdir_path, filename)
            if filename.endswith('.png'):
                image = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)
                clahe_image = apply_clahe(image)
                processed_file_path = os.path.join(train_processed_dir, subdir, filename)
                os.makedirs(os.path.dirname(processed_file_path), exist_ok=True)
                cv2.imwrite(processed_file_path, clahe_image)

for subdir in os.listdir(test_dir):
    subdir_path = os.path.join(test_dir, subdir)
    if os.path.isdir(subdir_path):
        print(f'Applying CLAHE to images in {subdir_path}...')
        for filename in os.listdir(subdir_path):
            file_path = os.path.join(subdir_path, filename)
            if filename.endswith('.png'):
                image = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)
                clahe_image = apply_clahe(image)
                processed_file_path = os.path.join(test_processed_dir, subdir, filename)
                os.makedirs(os.path.dirname(processed_file_path), exist_ok=True)
                cv2.imwrite(processed_file_path, clahe_image)

for subdir in os.listdir(valid_dir):
    subdir_path = os.path.join(valid_dir, subdir)
    if os.path.isdir(subdir_path):
        print(f'Applying CLAHE to images in {subdir_path}...')
        for filename in os.listdir(subdir_path):
            file_path = os.path.join(subdir_path, filename)
            if filename.endswith('.png'):
                image = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)
                clahe_image = apply_clahe(image)
                processed_file_path = os.path.join(valid_processed_dir, subdir, filename)
                os.makedirs(os.path.dirname(processed_file_path), exist_ok=True)
                cv2.imwrite(processed_file_path, clahe_image)
 
##################### marching in one folder #################

from tqdm import tqdm
import os
import cv2
import numpy as np

train_folder = train_processed_dir
valid_folder = valid_processed_dir
test_folder = test_processed_dir

X = []
y = []

class_labels = {'cancer': ['adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib', 'large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa', 'squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa'],
                'non-cancer': ['normal']}

for class_label, subfolders in class_labels.items():
    for subfolder in subfolders:
        folder_path = os.path.join(train_folder, subfolder)
        if os.path.isdir(folder_path):
            for filename in tqdm(os.listdir(folder_path)):
                img_path = os.path.join(folder_path, filename)
                img = cv2.imread(img_path)
                img = cv2.resize(img, (224, 224))
                X.append(img)
                y.append(class_label)

class_labels2 = {'cancer': ['adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib', 'large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa', 'squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa'],
                'non-cancer': ['normal']}
for class_label, subfolders in class_labels2.items():
    for subfolder in subfolders:
        folder_path = os.path.join(valid_folder, subfolder)
        if os.path.isdir(folder_path):
            for filename in tqdm(os.listdir(folder_path)):
                img_path = os.path.join(folder_path, filename)
                img = cv2.imread(img_path)
                img = cv2.resize(img, (224, 224))
                X.append(img)
                y.append(class_label)


class_labels3 = {'cancer': ['adenocarcinoma', 'large.cell.carcinoma', 'squamous.cell.carcinoma'],
                'non-cancer': ['normal']}
for class_label, subfolders in class_labels3.items():
    for subfolder in subfolders:
        folder_path = os.path.join(test_folder, subfolder)
        if os.path.isdir(folder_path):
            for filename in tqdm(os.listdir(folder_path)):
                img_path = os.path.join(folder_path, filename)
                img = cv2.imread(img_path)
                img = cv2.resize(img, (224, 224))
                X.append(img)
                y.append(class_label)

y_binary = np.array([0 if label == 'non-cancer' else 1 for label in y])



from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
print ("Shape of an image in X_train: ", X_train[0].shape)
print ("Shape of an image in X_test: ", X_test[0].shape)
from sklearn import preprocessing
le = preprocessing.LabelEncoder()
y_train = le.fit_transform(y_train)
y_test = le.fit_transform(y_test)
y_train = tf.keras.utils.to_categorical(y_train, num_classes=2)
y_test = tf.keras.utils.to_categorical(y_test, num_classes=2)
y_train = np.array(y_train)
X_train = np.array(X_train)
y_test = np.array(y_test)
X_test = np.array(X_test)
print("X_train Shape: ", X_train.shape)
print("X_test Shape: ", X_test.shape)
print("y_train Shape: ", y_train.shape)
print("y_test Shape: ", y_test.shape)


model = tf.keras.Sequential()
#1st conv layer
model.add(tf.keras.layers.Conv2D(32, 3, input_shape=(224, 224, 3)))
model.add(tf.keras.layers.BatchNormalization())
model.add(tf.keras.layers.Activation("relu"))
model.add(tf.keras.layers.MaxPooling2D(2))
#2nd conv layer
model.add(tf.keras.layers.Conv2D(64, 3, padding="valid"))
model.add(tf.keras.layers.BatchNormalization())
model.add(tf.keras.layers.Activation("relu"))
model.add(tf.keras.layers.MaxPooling2D(2))
#3rd conv layer (from here model gives good result)
model.add(tf.keras.layers.Conv2D(128, 3, padding="valid"))
model.add(tf.keras.layers.BatchNormalization())
model.add(tf.keras.layers.Activation("relu"))
model.add(tf.keras.layers.MaxPooling2D(2))
#4th conv layer
model.add(tf.keras.layers.Conv2D(256, 3, padding="valid"))
model.add(tf.keras.layers.BatchNormalization())
model.add(tf.keras.layers.Activation("relu"))
model.add(tf.keras.layers.MaxPooling2D(2))
#Flatten Layer
model.add(tf.keras.layers.Flatten())
#Dense Layer 1
model.add(tf.keras.layers.Dense(8000))
model.add(tf.keras.layers.BatchNormalization())
model.add(tf.keras.layers.Activation("relu"))
model.add(tf.keras.layers.Dropout(0.5))
model.add(tf.keras.layers.Dense(1024))
model.add(tf.keras.layers.BatchNormalization())
model.add(tf.keras.layers.Activation("relu"))
model.add(tf.keras.layers.Dropout(0.5))
model.add(tf.keras.layers.Dense(512,name ='feature_denseee'))   ### 512 prominent features extraction from this layer ###
model.add(tf.keras.layers.BatchNormalization())
model.add(tf.keras.layers.Activation("relu"))
model.add(tf.keras.layers.Dropout(0.5))
#Dense Layer 2
model.add(tf.keras.layers.Dense(100)) 
model.add(tf.keras.layers.BatchNormalization())
model.add(tf.keras.layers.Activation("relu"))
model.add(tf.keras.layers.Dropout(0.5))
#output Dense Layer
model.add(tf.keras.layers.Dense(2))
model.add(tf.keras.layers.Activation('softmax'))
adam = tf.keras.optimizers.Adam(lr=0.001)

model.compile(loss='categorical_crossentropy', metrics=['acc'], optimizer='adam')
model.summary()


history = model.fit(X_train, y_train, batch_size= 32, epochs=100, verbose=1, validation_data=(X_test, y_test))


plt.plot(history.history['acc'], label = 'train',)
plt.plot(history.history['val_acc'], label = 'valid')

plt.legend(loc = 'upper left')
plt.xlabel('epochs')
plt.ylabel('accuracy')
plt.show()
plt.plot(history.history['loss'], label = 'train',)
plt.plot(history.history['val_loss'], label = 'valid')

plt.legend(loc = 'upper left')
plt.xlabel('epochs')
plt.ylabel('loss')
plt.show()

model.save('/content/Data/model/lcancer.h5')
model = tf.keras.models.load_model('/content/Data/model/lcancer.h5')
intermediate_layer_model = tf.keras.Model(inputs=model.input, outputs=model.get_layer('feature_denseee').output)
intermediate_layer_model.summary()
X = np.array(X)
feature_engg_data = intermediate_layer_model.predict(X)
feature_engg_data = pd.DataFrame(feature_engg_data)
feature_engg_data.to_pickle('/content/Data/model/finalfeaturescovid.pkl')
features = pd.read_pickle('/content/Data/model/finalfeaturescovid.pkl')
from sklearn.preprocessing import StandardScaler
x = feature_engg_data.loc[:, feature_engg_data.columns].values
x = StandardScaler().fit_transform(x)
X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.20, stratify= y, random_state =0)
from sklearn.decomposition import TruncatedSVD

######################## feature reduced to 100 by svd ######################
svd = TruncatedSVD(n_components=100)
training_feature_svd_2D = svd.fit_transform(X_train)
test_feature_svd_2D = svd.transform(X_test)

############################################## gnb ####################
from sklearn.model_selection import cross_val_score, KFold
from sklearn import svm
from sklearn import metrics
from sklearn.metrics import confusion_matrix
from sklearn.metrics import roc_curve, auc
from sklearn.metrics import classification_report, accuracy_score, f1_score, recall_score, precision_score, roc_auc_score
from sklearn.preprocessing import label_binarize
from sklearn.naive_bayes import GaussianNB
from sklearn import  metrics
model = GaussianNB()
model.fit(training_feature_svd_2D, y_train)
y_pred1 = model.predict(test_feature_svd_2D)
metrics.accuracy_score(y_test, y_pred1)
print(metrics.accuracy_score(y_test, y_pred1))
print(metrics.classification_report(y_test, y_pred1))
y_pred_prob = model.predict_proba(test_feature_svd_2D)

confusion = confusion_matrix(y_test, y_pred1)

plt.figure(figsize=(8, 6))
sns.heatmap(confusion, annot=True, cmap='Blues', fmt='d')
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')
plt.show()

####################################### svm ###############################

from sklearn.svm import SVC

svm_model = SVC(probability=True)
svm_model.fit(training_feature_svd_2D, y_train)
y_pred_svm = svm_model.predict(test_feature_svd_2D)

svm_accuracy = metrics.accuracy_score(y_test, y_pred_svm)
print("SVM Accuracy:", svm_accuracy)

svm_classification_report = metrics.classification_report(y_test, y_pred_svm)
print("SVM Classification Report:\n", svm_classification_report)
y_pred_prob_svm = svm_model.predict_proba(test_feature_svd_2D)
svm_auc = roc_auc_score(y_test, y_pred_prob_svm[:, 1])
print("SVM AUC:", svm_auc)

#################### roc curve and cm for svm ###################
from sklearn.svm import SVC
from sklearn.metrics import roc_curve, auc, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

svm_model = SVC(probability=True)
svm_model.fit(training_feature_svd_2D, y_train)

from sklearn.preprocessing import LabelBinarizer

label_binarizer = LabelBinarizer()
y_test_binary = label_binarizer.fit_transform(y_test)

y_pred_prob_svm = svm_model.predict_proba(test_feature_svd_2D)[:, 1]

fpr_svm, tpr_svm, _ = roc_curve(y_test_binary, y_pred_prob_svm)
roc_auc_svm = auc(fpr_svm, tpr_svm)

plt.figure(figsize=(8, 6))
plt.plot(fpr_svm, tpr_svm, color='darkorange', lw=2, label='SVM ROC curve (AUC = %0.2f)' % roc_auc_svm)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc='lower right')
plt.show()

confusion_svm = confusion_matrix(y_test, y_pred_svm)

plt.figure(figsize=(8, 6))
sns.heatmap(confusion_svm, annot=True, cmap='Blues', fmt='d')
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix (SVM)')
plt.show()


############################################ roc and cm for gnb #########################

from sklearn.naive_bayes import GaussianNB

gnb_model = GaussianNB()
gnb_model.fit(training_feature_svd_2D, y_train)

y_pred_prob_gnb = gnb_model.predict_proba(test_feature_svd_2D)[:, 1]

fpr_gnb, tpr_gnb, _ = roc_curve(y_test_binary, y_pred_prob_gnb)
roc_auc_gnb = auc(fpr_gnb, tpr_gnb)

plt.figure(figsize=(8, 6))
plt.plot(fpr_gnb, tpr_gnb, color='green', lw=2, label='GNB ROC curve (AUC = %0.2f)' % roc_auc_gnb)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve (GNB)')
plt.legend(loc='lower right')
plt.show()

y_pred_gnb = gnb_model.predict(test_feature_svd_2D)
confusion_gnb = confusion_matrix(y_test, y_pred_gnb)

plt.figure(figsize=(8, 6))
sns.heatmap(confusion_gnb, annot=True, cmap='Blues', fmt='d')

plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix (GNB)')
plt.show()

############################################### roc and cm for gbm ############################

from sklearn.ensemble import GradientBoostingClassifier

gbm_model = GradientBoostingClassifier()
gbm_model.fit(training_feature_svd_2D, y_train)
y_pred_prob_gbm = gbm_model.predict_proba(test_feature_svd_2D)[:, 1]
fpr_gbm, tpr_gbm, _ = roc_curve(y_test_binary, y_pred_prob_gbm)
roc_auc_gbm = auc(fpr_gbm, tpr_gbm)

plt.figure(figsize=(8, 6))
plt.plot(fpr_gbm, tpr_gbm, color='blue', lw=2, label='GBM ROC curve (AUC = %0.2f)' % roc_auc_gbm)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve (GBM)')
plt.legend(loc='lower right')
plt.show()
y_pred_gbm = gbm_model.predict(test_feature_svd_2D)
confusion_gbm = confusion_matrix(y_test, y_pred_gbm)
plt.figure(figsize=(8, 6))
sns.heatmap(confusion_gbm, annot=True, cmap='Blues', fmt='d')
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix (GBM)')
plt.show()

################################################# roc and cm for knn #########################

from sklearn.neighbors import KNeighborsClassifier
knn_model = KNeighborsClassifier()
knn_model.fit(training_feature_svd_2D, y_train)

y_pred_prob_knn = knn_model.predict_proba(test_feature_svd_2D)[:, 1]

fpr_knn, tpr_knn, _ = roc_curve(y_test_binary, y_pred_prob_knn)
roc_auc_knn = auc(fpr_knn, tpr_knn)

plt.figure(figsize=(8, 6))
plt.plot(fpr_knn, tpr_knn, color='purple', lw=2, label='KNN ROC curve (AUC = %0.2f)' % roc_auc_knn)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve (KNN)')
plt.legend(loc='lower right')
plt.show()

y_pred_knn = knn_model.predict(test_feature_svd_2D)
confusion_knn = confusion_matrix(y_test, y_pred_knn)

plt.figure(figsize=(8, 6))
sns.heatmap(confusion_knn, annot=True, cmap='Blues', fmt='d')

plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix (KNN)')
plt.show()

############################################# roc and cm for rf ##############################

from sklearn.ensemble import RandomForestClassifier

rf_model = RandomForestClassifier()
rf_model.fit(training_feature_svd_2D, y_train)

y_pred_prob_rf = rf_model.predict_proba(test_feature_svd_2D)[:, 1]

fpr_rf, tpr_rf, _ = roc_curve(y_test_binary, y_pred_prob_rf)
roc_auc_rf = auc(fpr_rf, tpr_rf)

plt.figure(figsize=(8, 6))
plt.plot(fpr_rf, tpr_rf, color='red', lw=2, label='RF ROC curve (AUC = %0.2f)' % roc_auc_rf)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve (RF)')
plt.legend(loc='lower right')
plt.show()

y_pred_rf = rf_model.predict(test_feature_svd_2D)
confusion_rf = confusion_matrix(y_test, y_pred_rf)
plt.figure(figsize=(8, 6))
sns.heatmap(confusion_rf, annot=True, cmap='Blues', fmt='d')
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix (RF)')
plt.show()

################################################## voting classifier roc and cm #############################

from sklearn.ensemble import VotingClassifier
from sklearn.metrics import roc_curve, auc, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

gnb_model = GaussianNB()
gbm_model = GradientBoostingClassifier()
knn_model = KNeighborsClassifier()
svm_model = SVC(probability=True)
rf_model = RandomForestClassifier()

voting_classifier = VotingClassifier(estimators=[
    ('GNB', gnb_model),
    ('GBM', gbm_model),
    ('KNN', knn_model),
    ('SVM', svm_model),
    ('RF', rf_model)
], voting='soft')  # Use soft voting for probabilities

voting_classifier.fit(training_feature_svd_2D, y_train)

y_pred_prob_voting = voting_classifier.predict_proba(test_feature_svd_2D)[:, 1]

fpr_voting, tpr_voting, _ = roc_curve(y_test_binary, y_pred_prob_voting)
roc_auc_voting = auc(fpr_voting, tpr_voting)

plt.figure(figsize=(8, 6))
plt.plot(fpr_voting, tpr_voting, color='purple', lw=2, label='Voting ROC curve (AUC = %0.2f)' % roc_auc_voting)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve (Voting)')
plt.legend(loc='lower right')
plt.show()

y_pred_voting = voting_classifier.predict(test_feature_svd_2D)
confusion_voting = confusion_matrix(y_test, y_pred_voting)
plt.figure(figsize=(8, 6))
sns.heatmap(confusion_voting, annot=True, cmap='Blues', fmt='d')
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix (Voting)')
plt.show()

********** only result without roc curve and confusion matrix ************

************************** voting classifier classification *************************

from sklearn.ensemble import VotingClassifier
from sklearn.metrics import accuracy_score, classification_report, roc_auc_score
from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier

gnb_classifier = GaussianNB()
gbm_classifier = GradientBoostingClassifier()
knn_classifier = KNeighborsClassifier()
svm_classifier = SVC(probability=True)
rf_classifier = RandomForestClassifier()

voting_classifier = VotingClassifier(estimators=[
    ('GNB', gnb_classifier),
    ('GBM', gbm_classifier),
    ('KNN', knn_classifier),
    ('SVM', svm_classifier),
    ('RF', rf_classifier)
], voting='soft')  # Use soft voting for probabilities

voting_classifier.fit(training_feature_svd_2D, y_train)
y_pred_voting = voting_classifier.predict(test_feature_svd_2D)
voting_accuracy = accuracy_score(y_test, y_pred_voting)
print("Voting Classifier Accuracy:", voting_accuracy)
voting_classification_report = classification_report(y_test, y_pred_voting)
print("Voting Classifier Classification Report:\n", voting_classification_report)
y_pred_prob_voting = voting_classifier.predict_proba(test_feature_svd_2D)
voting_auc = roc_auc_score(y_test, y_pred_prob_voting[:, 1])
print("Voting Classifier AUC:", voting_auc)

****************************** gbm ***************************

from sklearn.ensemble import GradientBoostingClassifier
gbm_model = GradientBoostingClassifier()
gbm_model.fit(training_feature_svd_2D, y_train)
y_pred_gbm = gbm_model.predict(test_feature_svd_2D)
gbm_accuracy = metrics.accuracy_score(y_test, y_pred_gbm)
print("GBM Accuracy:", gbm_accuracy)
gbm_classification_report = metrics.classification_report(y_test, y_pred_gbm)
print("GBM Classification Report:\n", gbm_classification_report)
y_pred_prob_gbm = gbm_model.predict_proba(test_feature_svd_2D)
gbm_auc = roc_auc_score(y_test, y_pred_prob_gbm[:, 1])
print("GBM AUC:", gbm_auc)

*********************************** knn ************************

from sklearn.neighbors import KNeighborsClassifier
knn_model = KNeighborsClassifier()
knn_model.fit(training_feature_svd_2D, y_train)
y_pred_knn = knn_model.predict(test_feature_svd_2D)
knn_accuracy = metrics.accuracy_score(y_test, y_pred_knn)
print("KNN Accuracy:", knn_accuracy)
knn_classification_report = metrics.classification_report(y_test, y_pred_knn)
print("KNN Classification Report:\n", knn_classification_report)
y_pred_prob_knn = knn_model.predict_proba(test_feature_svd_2D)
knn_auc = roc_auc_score(y_test, y_pred_prob_knn[:, 1])
print("KNN AUC:", knn_auc)


**************************************** rf ********************************
from sklearn.ensemble import RandomForestClassifier
rf_model = RandomForestClassifier()
rf_model.fit(training_feature_svd_2D, y_train)
y_pred_rf = rf_model.predict(test_feature_svd_2D)
rf_accuracy = metrics.accuracy_score(y_test, y_pred_rf)
print("RF Accuracy:", rf_accuracy)
rf_classification_report = metrics.classification_report(y_test, y_pred_rf)
print("RF Classification Report:\n", rf_classification_report)
y_pred_prob_rf = rf_model.predict_proba(test_feature_svd_2D)
rf_auc = roc_auc_score(y_test, y_pred_prob_rf[:, 1])
print("RF AUC:", rf_auc)
