##### connect with kaggle & download ######
from google.colab import files
uploaded = files.upload()
for fn in uploaded.keys():
  print('User uploaded file "{name}" with length {length} bytes'.format(
      name=fn, length=len(uploaded[fn])))

!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download  --force mohamedhanyyy/chest-ctscan-images

##### import  necessary library ######

import numpy as np
import pandas as pd
import cv2
import matplotlib.pyplot as plt
import seaborn as sns
import os
from skimage import io
from skimage.color import rgb2gray
import plotly.express as px
import random
from sklearn.utils import shuffle
import shutil
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import OneHotEncoder
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential
from keras.layers import Dense, Flatten, Dropout, BatchNormalization, Conv2D, MaxPooling2D
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.applications.resnet import preprocess_input
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from keras import optimizers
from keras.applications import resnet

##### folder path ######

train_path = "/content/Data/train"
valid_path = "/content/Data/valid"
test_path = "/content/Data/test"

########### unzip ##########

from zipfile import ZipFile
file_name = "/content/chest-ctscan-images.zip"
with ZipFile(file_name,'r') as zip:
  zip.extractall()
  print('Done')

############################# pre-processed applying clahe #####################

import cv2
import os

def apply_clahe(image):
    clip_limit = 2.5
    tile_size = (8, 8)
    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_size)
    return clahe.apply(image)

train_dir = "/content/Data/train"
test_dir = "/content/Data/test"
valid_dir = "/content/Data/valid"

train_processed_dir = "/content/Data/train_processed"
test_processed_dir = "/content/Data/test_processed"
valid_processed_dir = "/content/Data/valid_processed"

os.makedirs(train_processed_dir, exist_ok=True)
os.makedirs(test_processed_dir, exist_ok=True)
os.makedirs(valid_processed_dir, exist_ok=True)

for subdir in os.listdir(train_dir):
    subdir_path = os.path.join(train_dir, subdir)
    if os.path.isdir(subdir_path):
        print(f'Applying CLAHE to images in {subdir_path}...')
        for filename in os.listdir(subdir_path):
            file_path = os.path.join(subdir_path, filename)
            if filename.endswith('.png'):
                image = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)
                clahe_image = apply_clahe(image)
                processed_file_path = os.path.join(train_processed_dir, subdir, filename)
                os.makedirs(os.path.dirname(processed_file_path), exist_ok=True)
                cv2.imwrite(processed_file_path, clahe_image)

for subdir in os.listdir(test_dir):
    subdir_path = os.path.join(test_dir, subdir)
    if os.path.isdir(subdir_path):
        print(f'Applying CLAHE to images in {subdir_path}...')
        for filename in os.listdir(subdir_path):
            file_path = os.path.join(subdir_path, filename)
            if filename.endswith('.png'):
                image = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)
                clahe_image = apply_clahe(image)
                processed_file_path = os.path.join(test_processed_dir, subdir, filename)
                os.makedirs(os.path.dirname(processed_file_path), exist_ok=True)
                cv2.imwrite(processed_file_path, clahe_image)

for subdir in os.listdir(valid_dir):
    subdir_path = os.path.join(valid_dir, subdir)
    if os.path.isdir(subdir_path):
        print(f'Applying CLAHE to images in {subdir_path}...')
        for filename in os.listdir(subdir_path):
            file_path = os.path.join(subdir_path, filename)
            if filename.endswith('.png'):
                image = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)
                clahe_image = apply_clahe(image)
                processed_file_path = os.path.join(valid_processed_dir, subdir, filename)
                os.makedirs(os.path.dirname(processed_file_path), exist_ok=True)
                cv2.imwrite(processed_file_path, clahe_image)


#####  merging in one folder  ######

from tqdm._tqdm_notebook import tqdm_notebook as tqdm
import os,glob
import cv2

import os
import cv2
from tqdm import tqdm

# train_folder = train_path
# valid_folder = valid_path
# test_folder = test_path

train_folder = train_processed_dir
valid_folder = valid_processed_dir
test_folder = test_processed_dir

X = []
y = []

for folder_name in os.listdir(train_folder):
    folder_path = os.path.join(train_folder, folder_name)
    if os.path.isdir(folder_path):
        for i in tqdm(os.listdir(folder_path)):
            img_path = os.path.join(folder_path, i)
            img = cv2.imread(img_path)
            img = cv2.resize(img, (224, 224))
            X.append(img)
            y.append(folder_name[0])

for folder_name in os.listdir(valid_folder):
    folder_path = os.path.join(valid_folder, folder_name)
    if os.path.isdir(folder_path):
        for i in tqdm(os.listdir(folder_path)):
            img_path = os.path.join(folder_path, i)
            img = cv2.imread(img_path)
            img = cv2.resize(img, (224, 224))
            X.append(img)
            y.append(folder_name[0])

for folder_name in os.listdir(test_folder):
    folder_path = os.path.join(test_folder, folder_name)
    if os.path.isdir(folder_path):
        for i in tqdm(os.listdir(folder_path)):
            img_path = os.path.join(folder_path, i)
            img = cv2.imread(img_path)
            img = cv2.resize(img, (224, 224))
            X.append(img)
            y.append(folder_name[0])


##### labelling and train-test splitting ######

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
print ("Shape of an image in X_train: ", X_train[0].shape)
print ("Shape of an image in X_test: ", X_test[0].shape)
from sklearn import preprocessing
le = preprocessing.LabelEncoder()
y_train = le.fit_transform(y_train)
y_test = le.fit_transform(y_test)
y_train = tf.keras.utils.to_categorical(y_train, num_classes=4)
y_test = tf.keras.utils.to_categorical(y_test, num_classes=4)
y_train = np.array(y_train)
X_train = np.array(X_train)
y_test = np.array(y_test)
X_test = np.array(X_test)
print("X_train Shape: ", X_train.shape)
print("X_test Shape: ", X_test.shape)
print("y_train Shape: ", y_train.shape)
print("y_test Shape: ", y_test.shape)



##### cnn-model #####
model = tf.keras.Sequential()
#1st conv layer
model.add(tf.keras.layers.Conv2D(32, 3, input_shape=(224, 224, 3)))
model.add(tf.keras.layers.BatchNormalization())
model.add(tf.keras.layers.Activation("relu"))
model.add(tf.keras.layers.MaxPooling2D(2))
#2nd conv layer
model.add(tf.keras.layers.Conv2D(64, 3, padding="valid"))
model.add(tf.keras.layers.BatchNormalization())
model.add(tf.keras.layers.Activation("relu"))
model.add(tf.keras.layers.MaxPooling2D(2))
#3rd conv layer (from here model gives good result)
model.add(tf.keras.layers.Conv2D(128, 3, padding="valid"))
model.add(tf.keras.layers.BatchNormalization())
model.add(tf.keras.layers.Activation("relu"))
model.add(tf.keras.layers.MaxPooling2D(2))
#4th conv layer
model.add(tf.keras.layers.Conv2D(256, 3, padding="valid"))
model.add(tf.keras.layers.BatchNormalization())
model.add(tf.keras.layers.Activation("relu"))
model.add(tf.keras.layers.MaxPooling2D(2))
#Flatten Layer
model.add(tf.keras.layers.Flatten())
#Dense Layer 1
model.add(tf.keras.layers.Dense(8000))
model.add(tf.keras.layers.BatchNormalization())
model.add(tf.keras.layers.Activation("relu"))
model.add(tf.keras.layers.Dropout(0.5))
model.add(tf.keras.layers.Dense(1024))
model.add(tf.keras.layers.BatchNormalization())
model.add(tf.keras.layers.Activation("relu"))
model.add(tf.keras.layers.Dropout(0.5))
model.add(tf.keras.layers.Dense(512,name ='feature_denseee'))   ### 512 prominent features extraction from this layer ###
model.add(tf.keras.layers.BatchNormalization())
model.add(tf.keras.layers.Activation("relu"))
model.add(tf.keras.layers.Dropout(0.5))
#Dense Layer 2
model.add(tf.keras.layers.Dense(100)) #100 Prominant Features are Extracted From This Layer
model.add(tf.keras.layers.BatchNormalization())
model.add(tf.keras.layers.Activation("relu"))
model.add(tf.keras.layers.Dropout(0.5))
#output Dense Layer
model.add(tf.keras.layers.Dense(4))
model.add(tf.keras.layers.Activation('softmax'))
adam = tf.keras.optimizers.Adam(lr=0.001)

model.compile(loss='categorical_crossentropy', metrics=['acc'], optimizer='adam')
model.summary()

history = model.fit(X_train, y_train, batch_size= 32, epochs=100, verbose=1, validation_data=(X_test, y_test))

plt.plot(history.history['acc'], label = 'train',)
plt.plot(history.history['val_acc'], label = 'valid')

plt.legend(loc = 'upper left')
plt.xlabel('epochs')
plt.ylabel('accuracy')
plt.show()

plt.plot(history.history['loss'], label = 'train',)
plt.plot(history.history['val_loss'], label = 'valid')

plt.legend(loc = 'upper left')
plt.xlabel('epochs')
plt.ylabel('loss')
plt.show()

##### save the model , model loading and feature saving #####

model.save('/content/Data/model/lungcancer.h5')
model = tf.keras.models.load_model('/content/Data/model/lungcancer.h5')
intermediate_layer_model = tf.keras.Model(inputs=model.input, outputs=model.get_layer('feature_denseee').output)
intermediate_layer_model.summary()

X = np.array(X)
feature_engg_data = intermediate_layer_model.predict(X)
feature_engg_data = pd.DataFrame(feature_engg_data)
feature_engg_data.to_pickle('/content/Data/model/finalfeaturescovid.pkl')
features = pd.read_pickle('/content/Data/model/finalfeaturescovid.pkl')
from sklearn.preprocessing import StandardScaler
x = feature_engg_data.loc[:, feature_engg_data.columns].values
x = StandardScaler().fit_transform(x)
X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.20, stratify= y, random_state =0)


################################### svd  ##########################
from sklearn.decomposition import TruncatedSVD

svd = TruncatedSVD(n_components=100)
training_feature_svd_2D = svd.fit_transform(X_train)
test_feature_svd_2D = svd.transform(X_test)


                     '''''''''''''''''''''''''''''''''''''''''GNB''''''''''''''''''''''''''''''''
from sklearn.model_selection import cross_val_score, KFold
from sklearn import svm
from sklearn import metrics
from sklearn.metrics import confusion_matrix
from sklearn.metrics import roc_curve, auc
from sklearn.metrics import classification_report, accuracy_score, f1_score, recall_score, precision_score, roc_auc_score
from sklearn.preprocessing import label_binarize
from sklearn.naive_bayes import GaussianNB
from sklearn import  metrics
model = GaussianNB()
model.fit(training_feature_svd_2D, y_train)
y_pred1 = model.predict(test_feature_svd_2D)
metrics.accuracy_score(y_test, y_pred1)
print(metrics.accuracy_score(y_test, y_pred1))
print(metrics.classification_report(y_test, y_pred1))
y_pred_prob = model.predict_proba(test_feature_svd_2D)
auc = roc_auc_score(y_test, y_pred_prob, multi_class='ovr')
print("AUC:", auc)

import matplotlib.pyplot as plt
import seaborn as sns
confusion = confusion_matrix(y_test, y_pred1)

plt.figure(figsize=(8, 6))
sns.heatmap(confusion, annot=True, cmap='Blues', fmt='d')
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')
plt.show()

                                            ''''''''''roc curve for gnb'''''''''
# Compute ROC curve for each class
n_classes = len(np.unique(y_test))
y_test_bin = label_binarize(y_test, classes=np.unique(y_test))

fpr = dict()
tpr = dict()
roc_auc_scores = dict()  
for i in range(n_classes):
    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_pred_prob[:, i])
    roc_auc_scores[i] = roc_auc_score(y_test_bin[:, i], y_pred_prob[:, i])  
fpr["micro"], tpr["micro"], _ = roc_curve(y_test_bin.ravel(), y_pred_prob.ravel())
roc_auc_scores["micro"] = roc_auc_score(y_test_bin, y_pred_prob, average='micro')  

plt.figure(figsize=(8, 6))
for i in range(n_classes):
    plt.plot(fpr[i], tpr[i], label='ROC curve (area = {:.2f}) for class {}'.format(roc_auc_scores[i], i))

plt.plot(fpr["micro"], tpr["micro"], label='Micro-average ROC curve (area = {:.2f})'.format(roc_auc_scores["micro"]), linestyle=':', linewidth=4)

plt.plot([0, 1], [0, 1], 'k--')  
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc='lower right')
plt.show()


'''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''GBM''''''''''''''''''''''
from sklearn.ensemble import GradientBoostingClassifier
import sklearn.metrics as metrics
gbm_classifier = GradientBoostingClassifier()
gbm_classifier.fit(training_feature_svd_2D, y_train)
y_pred_gbm = gbm_classifier.predict(test_feature_svd_2D)
accuracy = metrics.accuracy_score(y_test, y_pred_gbm)
print("Accuracy:", accuracy)
classification_report = metrics.classification_report(y_test, y_pred_gbm)
y_pred_prob_gbm = gbm_classifier.predict_proba(test_feature_svd_2D)
classification_report = metrics.classification_report(y_test, y_pred_gbm)
print("Classification Report:\n", classification_report)
auc = metrics.roc_auc_score(y_test, y_pred_prob_gbm, multi_class='ovr')
print("AUC:", auc)
import matplotlib.pyplot as plt
import seaborn as sns
confusion_matrix_gbm = metrics.confusion_matrix(y_test, y_pred_gbm)
plt.figure(figsize=(8, 6))
sns.heatmap(confusion_matrix_gbm, annot=True, cmap='Blues', fmt='d')
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix - GBM')
plt.show()

############################################### roc curve for gbm #####################
# Compute ROC curve for each class
n_classes = len(np.unique(y_test))
y_test_bin = label_binarize(y_test, classes=np.unique(y_test))

fpr = dict()
tpr = dict()
roc_auc_scores = dict()  # Renamed the dictionary variable
for i in range(n_classes):
    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_pred_prob_gbm[:, i])
    roc_auc_scores[i] = roc_auc_score(y_test_bin[:, i], y_pred_prob_gbm[:, i])  

fpr["micro"], tpr["micro"], _ = roc_curve(y_test_bin.ravel(), y_pred_prob_gbm.ravel())
roc_auc_scores["micro"] = roc_auc_score(y_test_bin, y_pred_prob_gbm, average='micro')  
plt.figure(figsize=(8, 6))
for i in range(n_classes):
    plt.plot(fpr[i], tpr[i], label='ROC curve (area = {:.2f}) for class {}'.format(roc_auc_scores[i], i))

plt.plot(fpr["micro"], tpr["micro"], label='Micro-average ROC curve (area = {:.2f})'.format(roc_auc_scores["micro"]), linestyle=':', linewidth=4)

plt.plot([0, 1], [0, 1], 'k--')  # Plot the random guessing curve
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc='lower right')
plt.show()


"'''''''''''''''''''''''''''''''''''''''''''''''''''''''''''SVM'''''''''''''''''''''''''''''''''''

from sklearn.svm import SVC
svclassifier = SVC(kernel='sigmoid', probability=True)
svclassifier.fit(training_feature_svd_2D , y_train)
y_pred2 = svclassifier.predict(test_feature_svd_2D)
metrics.accuracy_score(y_test, y_pred2)
print(metrics.classification_report(y_test, y_pred2))
print(metrics.accuracy_score(y_test, y_pred2))
y_pred_prob_svm = svclassifier.predict_proba(test_feature_svd_2D)
auc = roc_auc_score(y_test, y_pred_prob_svm, multi_class='ovr')
print("AUC:", auc)
import matplotlib.pyplot as plt
import seaborn as sns
confusion = confusion_matrix(y_test, y_pred2)
plt.figure(figsize=(8, 6))
sns.heatmap(confusion, annot=True, cmap='Blues', fmt='d')
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')
plt.show()

################################################ roc curve for svm ##############################

n_classes = len(np.unique(y_test))
y_test_bin = label_binarize(y_test, classes=np.unique(y_test))
fpr = dict()
tpr = dict()
roc_auc_scores = dict()  
for i in range(n_classes):
    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_pred_prob_svm[:, i])
    roc_auc_scores[i] = roc_auc_score(y_test_bin[:, i], y_pred_prob_svm[:, i])  
# Compute micro-average ROC curve and AUC
fpr["micro"], tpr["micro"], _ = roc_curve(y_test_bin.ravel(), y_pred_prob_svm.ravel())
roc_auc_scores["micro"] = roc_auc_score(y_test_bin, y_pred_prob_svm, average='micro')  

plt.figure(figsize=(8, 6))
for i in range(n_classes):
    plt.plot(fpr[i], tpr[i], label='ROC curve (area = {:.2f}) for class {}'.format(roc_auc_scores[i], i))
plt.plot(fpr["micro"], tpr["micro"], label='Micro-average ROC curve (area = {:.2f})'.format(roc_auc_scores["micro"]), linestyle=':', linewidth=4)
plt.plot([0, 1], [0, 1], 'k--') 
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc='lower right')
plt.show()


'''''''''''''''''''''''''''''''''''''''''''''''''''''''KNN'''''''''''''''''''''' 

from sklearn.neighbors import KNeighborsClassifier
from sklearn import metrics
import matplotlib.pyplot as plt
import seaborn as sns
knn = KNeighborsClassifier()
knn.fit(training_feature_svd_2D, y_train)
y_pred3 = knn.predict(test_feature_svd_2D)
accuracy = metrics.accuracy_score(y_test, y_pred3)
print("Accuracy:", accuracy)
classification_report = metrics.classification_report(y_test, y_pred3)
print("Classification Report:\n", classification_report)
y_pred_prob_knn = knn.predict_proba(test_feature_svd_2D)
auc = metrics.roc_auc_score(y_test, y_pred_prob_knn, multi_class='ovr')
print("AUC:", auc)
confusion = metrics.confusion_matrix(y_test, y_pred3)
plt.figure(figsize=(8, 6))
sns.heatmap(confusion, annot=True, cmap='Blues', fmt='d')
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')
plt.show()

######################################################### roc for knn ########################################

n_classes = len(np.unique(y_test))
y_test_bin = label_binarize(y_test, classes=np.unique(y_test))

fpr = dict()
tpr = dict()
roc_auc_scores = dict()  
for i in range(n_classes):
    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_pred_prob_knn[:, i])
    roc_auc_scores[i] = roc_auc_score(y_test_bin[:, i], y_pred_prob_knn[:, i])  
fpr["micro"], tpr["micro"], _ = roc_curve(y_test_bin.ravel(), y_pred_prob_knn.ravel())
roc_auc_scores["micro"] = roc_auc_score(y_test_bin, y_pred_prob_knn, average='micro')  

plt.figure(figsize=(8, 6))
for i in range(n_classes):
    plt.plot(fpr[i], tpr[i], label='ROC curve (area = {:.2f}) for class {}'.format(roc_auc_scores[i], i))

plt.plot(fpr["micro"], tpr["micro"], label='Micro-average ROC curve (area = {:.2f})'.format(roc_auc_scores["micro"]), linestyle=':', linewidth=4)

plt.plot([0, 1], [0, 1], 'k--')  
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc='lower right')
plt.show()



'''''''''''''''''''''''''''''''''''''''''''''''''''''''RF'''''''''''''''''''''''''''''''''''''''

from sklearn.ensemble import RandomForestClassifier
RF = RandomForestClassifier(n_estimators=50, random_state=1)
RF = RF.fit(training_feature_svd_2D, y_train)
y_pred5 = RF.predict(test_feature_svd_2D)
print(metrics.accuracy_score(y_test, y_pred5))
print(metrics.classification_report(y_test, y_pred5))
y_pred_prob_rf = RF.predict_proba(test_feature_svd_2D)

auc = roc_auc_score(y_test, y_pred_prob_rf, multi_class='ovr')
print("AUC:", auc)
import matplotlib.pyplot as plt
import seaborn as sns
confusion = confusion_matrix(y_test, y_pred5)

plt.figure(figsize=(8, 6))
sns.heatmap(confusion, annot=True, cmap='Blues', fmt='d')
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')
plt.show()

############################################################ roc for rf ###############################


# Compute ROC curve for each class
n_classes = len(np.unique(y_test))
y_test_bin = label_binarize(y_test, classes=np.unique(y_test))

fpr = dict()
tpr = dict()
roc_auc_scores = dict() 
for i in range(n_classes):
    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_pred_prob_rf[:, i])
    roc_auc_scores[i] = roc_auc_score(y_test_bin[:, i], y_pred_prob_rf[:, i])  

fpr["micro"], tpr["micro"], _ = roc_curve(y_test_bin.ravel(), y_pred_prob_rf.ravel())
roc_auc_scores["micro"] = roc_auc_score(y_test_bin, y_pred_prob_rf, average='micro')  

plt.figure(figsize=(8, 6))
for i in range(n_classes):
    plt.plot(fpr[i], tpr[i], label='ROC curve (area = {:.2f}) for class {}'.format(roc_auc_scores[i], i))

plt.plot(fpr["micro"], tpr["micro"], label='Micro-average ROC curve (area = {:.2f})'.format(roc_auc_scores["micro"]), linestyle=':', linewidth=4)

plt.plot([0, 1], [0, 1], 'k--') 
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc='lower right')
plt.show()




''''''''''''''''''''''''''''''''''''''''''''''''''''''VOTING CLASSIFIER''''''''''''''''''''''''''''''''''

from sklearn.metrics import classification_report, roc_auc_score
from sklearn.preprocessing import LabelEncoder, OneHotEncoder
from sklearn.ensemble import VotingClassifier


voting_classifier = VotingClassifier(estimators=[('gbm_classifier', gbm_classifier), ('svm', svclassifier), ('knn', knn), ('GNB', model), ('rf', RF)], voting='hard')
voting_classifier.fit(training_feature_svd_2D, y_train)

y_pred_vot = voting_classifier.predict(test_feature_svd_2D)

label_encoder = LabelEncoder()
y_test_encoded = label_encoder.fit_transform(y_test)
y_pred_encoded = label_encoder.transform(y_pred_vot)

onehot_encoder = OneHotEncoder(sparse=False)
y_test_onehot = onehot_encoder.fit_transform(y_test_encoded.reshape(-1, 1))
y_pred_onehot = onehot_encoder.transform(y_pred_encoded.reshape(-1, 1))

accuracy = metrics.accuracy_score(y_test_encoded, y_pred_encoded)
report = classification_report(y_test_encoded, y_pred_encoded)
auc = roc_auc_score(y_test_onehot, y_pred_onehot, multi_class='ovo')

print("Accuracy:", accuracy)
print("Classification Report:\n", report)
print("AUC:", auc)

from sklearn.metrics import classification_report, accuracy_score, roc_auc_score, precision_score, recall_score, f1_score


precision = precision_score(y_test_encoded, y_pred_encoded, average='macro')
recall = recall_score(y_test_encoded, y_pred_encoded, average='macro')
f1 = f1_score(y_test_encoded, y_pred_encoded, average='macro')

# Print precision, recall, F1-score
print("Precision:", precision)
print("Recall:", recall)
print("F1-score:", f1)

################################################## roc for voting classifier ######################

from sklearn.metrics import classification_report, roc_auc_score, roc_curve, auc
import matplotlib.pyplot as plt


voting_classifier = VotingClassifier(estimators=[('gbm_classifier', gbm_classifier), ('svm', svclassifier), ('knn', knn), ('GNB', model), ('rf', RF)], voting='soft')
voting_classifier.fit(training_feature_svd_2D, y_train)

y_pred_vot_prob = voting_classifier.predict_proba(test_feature_svd_2D)

label_encoder = LabelEncoder()
y_test_encoded = label_encoder.fit_transform(y_test)

fpr = dict()
tpr = dict()
roc_auc_dict = dict() 
n_classes = len(label_encoder.classes_)
for i in range(n_classes):
    fpr[i], tpr[i], _ = roc_curve(y_test_onehot[:, i], y_pred_vot_prob[:, i])
    roc_auc_dict[i] = auc(fpr[i], tpr[i]) 

fpr["micro"], tpr["micro"], _ = roc_curve(y_test_onehot.ravel(), y_pred_vot_prob.ravel())
roc_auc_dict["micro"] = auc(fpr["micro"], tpr["micro"])  

plt.figure(figsize=(8, 6))
for i in range(n_classes):
    plt.plot(fpr[i], tpr[i], label='ROC curve (area = {:.2f}) for class {}'.format(roc_auc_dict[i], label_encoder.classes_[i]))

plt.plot(fpr["micro"], tpr["micro"], label='Micro-average ROC curve (area = {:.2f})'.format(roc_auc_dict["micro"]), linestyle=':', linewidth=4)

plt.plot([0, 1], [0, 1], 'k--')  
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc='lower right')
plt.show()

